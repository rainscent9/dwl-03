{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78137f17-aa56-4040-81e7-8adf7c239471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-1.3.4-cp39-cp39-win_amd64.whl (10.2 MB)\n",
      "Collecting numpy>=1.17.3\n",
      "  Using cached numpy-1.21.3-cp39-cp39-win_amd64.whl (14.0 MB)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\simub\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\simub\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\simub\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: numpy, pandas\n",
      "Successfully installed numpy-1.21.3 pandas-1.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e496303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 # make --> pip install boto3\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import io\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa68e4-f8c4-449f-9b77-d88f4b7b0ab4",
   "metadata": {},
   "source": [
    "# S3 credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1131dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Accessing the S3 buckets using boto3 client\"\"\"\n",
    "s3_client = boto3.client('s3')\n",
    "s3_bucket_name='datalake-eldorado'\n",
    "s3 = boto3.resource('s3',\n",
    "                    aws_access_key_id='ASIATZQUBIR7ZB7D5356',\n",
    "                    aws_secret_access_key='8dSodA6262SD8ZI5Jf+0dPCsmKP/osv56u75Jd2D',\n",
    "                    aws_session_token='FwoGZXIvYXdzEPH//////////wEaDEb33y48gRHiI19flCK5AcQqoKmOAXOSYPHv5VBHqQTVefkAJz8BI3EuAVdRi4UOwYvHa90IfD2ZCLOCF1DBDH4/HsoPLYLbowx+vE/1gIU4jXLVmx0cefkRt0hsokBeanEYXy+HJTPiPSAwuaf34f+xJEowBkPfX3jRHhM7yGmU7ON/IXuA1rg1MvXcWF4gtfqM82QU0K1uKwru75JSMxnsIuYuAE3EtGxFq40iEZRGZlyQlgJSxQh0qepZyA7Rk5sv7F/eDgz7KN7E4IsGMi2LZx7GjzSyCbLZ6PnFd3KjTr9OYB6GgZM1GBfc998QdBGeFZ+lkpzG8IWziNM=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad48972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Getting data files from the AWS S3 bucket as denoted above and printing the first 10 file names having prefix \"2019/7/8\" \"\"\"\n",
    "my_bucket=s3.Bucket(s3_bucket_name)\n",
    "\n",
    "for my_bucket_object in my_bucket.objects.all():\n",
    "    print(my_bucket_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12d8b8-2c12-4a50-b6e8-fda82cf6ce27",
   "metadata": {},
   "source": [
    "# YAHOO Finance API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7762fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error occured\n"
     ]
    }
   ],
   "source": [
    "## Basic url\n",
    "url = \"https://yfapi.net/v6/finance/quote?\"\n",
    "\n",
    "querystring = {'symbols':'CS', # if many: 'symbols':'AAPL,BTC-USD,EURUSD=X'\n",
    "               'region':'US',\n",
    "               'lang':'en-US'}\n",
    "\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'x-api-key': 'TZ1z5Ndk7010iPfALDXa15jAIuLnzLVD2DSFik9e'\n",
    "    }\n",
    " \n",
    "try:\n",
    "    response = requests.get(url, headers=headers, params=querystring, timeout=5)\n",
    "    response.raise_for_status()\n",
    "    # Code here will only run if the request is successful\n",
    "    print('The request was a success!')\n",
    "    print(response.json())\n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print('HTTP Error occured')\n",
    "except requests.exceptions.ConnectionError as errc:\n",
    "    print('Connection Error occured')\n",
    "except requests.exceptions.Timeout as errt:\n",
    "    print('Timeout Error occured')\n",
    "except requests.exceptions.RequestException as err:\n",
    "    print('Request Exception Error occured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f1a48c1-667b-4d67-b204-be77b224fb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Limit Exceeded'}\n"
     ]
    }
   ],
   "source": [
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b1f30c9-f31a-4cb9-857e-7afd127ebae9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'quoteResponse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17176/1098861196.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'quoteResponse'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0md1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'quoteResponse'"
     ]
    }
   ],
   "source": [
    "r = response.json()['quoteResponse']['result']\n",
    "d1 = r[0]\n",
    "l1 = list(d1.values())\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c05e822b-a9ee-42e2-b8bb-aed04d82753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.splitgraph.com/ -> request your own user/password\n",
    "config = {\n",
    "    'host': 'datalake-1.cjwwzyskcblj.us-east-1.rds.amazonaws.com',\n",
    "    'port': '5432',\n",
    "    'user': 'simon',\n",
    "    'password': '!GM4Ltcd',\n",
    "    'dbname': 'datalake1',\n",
    "}\n",
    "def setup_db_connection():\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=config['dbname'],\n",
    "        user=config['user'],\n",
    "        host=config['host'],\n",
    "        password=config['password'],\n",
    "        port=config['port'],\n",
    "    )\n",
    "    #db_conn.autocommit = True  # Used to write to the database without the need for COMMIT\n",
    "    #cursor = conn.cursor()  # simple cursor that returns records as list of values\n",
    "    cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)  # returns records quasi as dictionaries \n",
    "    return conn, cursor\n",
    "\n",
    "conn, cursor = setup_db_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da55d91c-663a-407a-8ec6-93a458ddb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "    INSERT INTO yahoofin\n",
    "    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,\n",
    "            %s,%s,%s,%s,%s,%s,%s,%s,%s,%s,\n",
    "            %s,%s,%s,%s,%s,%s,%s,%s,%s,%s,\n",
    "            %s,%s,%s,%s,%s,%s,%s,%s,%s,%s,\n",
    "            %s,%s,%s,%s,%s,%s,%s,%s,%s,%s,\n",
    "            %s,%s,%s,%s,%s,%s,%s,%s,%s,%s,\n",
    "            %s,%s,%s,%s,%s,%s,%s,%s,%s);\n",
    "'''\n",
    "param=tuple(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2229472-fd91-4399-b5e0-fd088c001fd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "InFailedSqlTransaction",
     "evalue": "current transaction is aborted, commands ignored until end of transaction block\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInFailedSqlTransaction\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5932/2945828176.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\switchdrive\\Private\\HS21\\DWL03 Data Warehouse and Data Lakes\\01_DWL_Python\\venv\\lib\\site-packages\\psycopg2\\extras.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, query, vars)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_mapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query_executed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcallproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInFailedSqlTransaction\u001b[0m: current transaction is aborted, commands ignored until end of transaction block\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(sql, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d635683-48a3-4792-9362-b8b3f513be9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf99e7dc-beef-4236-9787-19ff675d7380",
   "metadata": {},
   "source": [
    "# S3 upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b28a0ef-e8c6-4584-92fc-dce847ae4805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.MultipartUpload(bucket_name='response.text', object_key='datalake-eldorado', id='yahoofinance/')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.MultipartUpload('response.text', 'datalake-eldorado', 'yahoofinance/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24043dfe-6c90-464f-a0d5-d80db50fc301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Uploaded Successfully\n"
     ]
    }
   ],
   "source": [
    "## Set bucket, key/file name\n",
    "object = s3.Object('datalake-eldorado', 'yahoofinance/test3.json')\n",
    "## put the API response into the bucket under the above set path and name\n",
    "result = object.put(Body=response.text)\n",
    "res = result.get('ResponseMetadata')\n",
    "if res.get('HTTPStatusCode') == 200:\n",
    "    print('File Uploaded Successfully')\n",
    "else:\n",
    "    print('File Not Uploaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677cae4-b502-41b6-be73-e84b61f1b37b",
   "metadata": {},
   "source": [
    "# Scrape Reddit\n",
    "https://gilberttanner.com/blog/scraping-redditdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b8bd5fc-9d95-4374-a288-9780b6eda540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Using cached praw-7.4.0-py3-none-any.whl (167 kB)\n",
      "Collecting update-checker>=0.18\n",
      "  Using cached update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting websocket-client>=0.54.0\n",
      "  Using cached websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
      "Collecting prawcore<3,>=2.1\n",
      "  Using cached prawcore-2.3.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\simub\\switchdrive\\private\\hs21\\dwl03 data warehouse and data lakes\\01_dwl_python\\venv\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.26.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simub\\switchdrive\\private\\hs21\\dwl03 data warehouse and data lakes\\01_dwl_python\\venv\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\simub\\switchdrive\\private\\hs21\\dwl03 data warehouse and data lakes\\01_dwl_python\\venv\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\simub\\switchdrive\\private\\hs21\\dwl03 data warehouse and data lakes\\01_dwl_python\\venv\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\simub\\switchdrive\\private\\hs21\\dwl03 data warehouse and data lakes\\01_dwl_python\\venv\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.7)\n",
      "Installing collected packages: websocket-client, update-checker, prawcore, praw\n",
      "Successfully installed praw-7.4.0 prawcore-2.3.0 update-checker-0.18.0 websocket-client-1.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\simub\\switchdrive\\Private\\HS21\\DWL03 Data Warehouse and Data Lakes\\01_DWL_Python\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49dc6617-8e79-4c94-b33c-57aa7b967d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb31e8a2-b507-4fa3-8b74-7b04c2d8287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='-MMHAO8_KhzUnKvJ09aVKg', client_secret='n3qSMav-eQST5TCjAE2GNktgFc5Ogw', user_agent='Airflow Scraper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59691664-0cb3-4400-ba32-ed6a397967f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D] Machine Learning - WAYR (What Are You Reading) - Week 124\n",
      "[D] Simple Questions Thread\n",
      "[R] Neurips 2021 Accepted Paper List\n",
      "[D] Why do we apply batch normalization between layers\n",
      "[D] What do Machine Learning Engineers at Facebook do?\n",
      "[P] Text-to-image models ruDALL-E Kandinsky (XXL) (12 billion parameters) and ruDALL-E Malevich (XL) (1.3 billion parameters). A demo for the latter is available.\n",
      "[D] Neural architecture search and Neuroevolution\n",
      "[D] Did anyone check ykilcher's video of Siraj Raval's interview\n",
      "[N] Amazon Externalizes MLU-Explain: Interactive (d3.js) \"Explainer\" Articles Covering Machine Learning Concepts\n",
      "[D] Why hasn't BERT been scaled up/trained on a massive dataset like GPT3?\n"
     ]
    }
   ],
   "source": [
    "hot_posts = reddit.subreddit('MachineLearning').hot(limit=10)\n",
    "for post in hot_posts:\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de3f4698-6e75-4d95-8e8e-b4af7af68403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  score      id subreddit  \\\n",
      "0  Man killed his daughter's boyfriend for sellin...  30721  ql7fwk      news   \n",
      "1  Kyle Rittenhouse chased down an unarmed man an...   9034  ql99fe      news   \n",
      "2  Woman reaches into purse, accidentally fires g...  38797  ql3ew8      news   \n",
      "3  College costs have increased by 169% since 198...   2837  qlam1j      news   \n",
      "4  9,000 NYC workers on unpaid leave for not comp...   3420  ql3zor      news   \n",
      "5  Zillow says it's closing home-buying business ...    699  qldtfc      news   \n",
      "6  New blood test can spot more than 50 types of ...    583  qldxz0      news   \n",
      "7     Virginia pastor arrested in prostitution sting    501  qlc93z      news   \n",
      "8  Half of Beijingâ€™s flights are cancelled as Chi...   1359  ql1pzh      news   \n",
      "9  World is failing to make changes needed to avo...    147  qlfhd8      news   \n",
      "\n",
      "                                                 url  num_comments body  \\\n",
      "0  https://www.nbcnews.com/news/us-news/man-kille...          3501        \n",
      "1  https://www.cnn.com/2021/11/02/us/kyle-rittenh...          1146        \n",
      "2  https://www.wlox.com/2021/11/02/woman-reaches-...          6657        \n",
      "3  https://www.cnbc.com/2021/11/02/the-gap-in-col...           270        \n",
      "4  https://www.cnn.com/2021/11/02/us/nyc-fdny-fir...           409        \n",
      "5  https://www.cnbc.com/2021/11/02/zillow-shares-...           114        \n",
      "6  https://www.cbsnews.com/news/cancer-blood-test...            71        \n",
      "7  https://www.nbcnews.com/news/us-news/virginia-...            75        \n",
      "8  https://www.cnbc.com/2021/11/02/beijing-flight...           180        \n",
      "9  https://www.theguardian.com/environment/2021/o...            47        \n",
      "\n",
      "        created  \n",
      "0  1.635869e+09  \n",
      "1  1.635874e+09  \n",
      "2  1.635857e+09  \n",
      "3  1.635877e+09  \n",
      "4  1.635859e+09  \n",
      "5  1.635886e+09  \n",
      "6  1.635886e+09  \n",
      "7  1.635882e+09  \n",
      "8  1.635851e+09  \n",
      "9  1.635891e+09  \n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "news_subreddit = reddit.subreddit('News')\n",
    "for post in news_subreddit.hot(limit=10):\n",
    "    posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created])\n",
    "posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])\n",
    "print(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b5f0b7-d3ff-4a19-bd66-2aa58a9b6b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datawarehouse1",
   "language": "python",
   "name": "datawarehouse1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
